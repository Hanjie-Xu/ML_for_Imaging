{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hanjie-Xu/ML_for_Imaging/blob/main/tutorial_1_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60JJ2_MqUwiO"
      },
      "source": [
        "# Tutorial 1 - Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cdqu8kccUwiS"
      },
      "source": [
        "In this tutorial, we will first revisit a logistic-regression like approach for the MNIST classification task. This time we will be using PyTorch and PyTorch Lightning for the implementation, training, and testing. The task is then two replace the single-layer neural network with a convolutional neural network such as LeNet. We will compare the performance of the approaches on an out-of-distribution test set where digits have been slightly shifted.\n",
        "\n",
        "**Objective:** Use PyTorch and PyTorch Lightning for the development of deep neural networks for image classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-NeoBfBUwiT"
      },
      "outputs": [],
      "source": [
        "# On Google Colab uncomment the following line to install PyTorch Lightning\n",
        "# ! pip install lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mE1J4u7SUwiV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from pytorch_lightning import LightningModule, LightningDataModule, Trainer, seed_everything\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar\n",
        "from torchmetrics.functional import accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOBkoy2zUwiV"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCZ6kqFPUwiW"
      },
      "source": [
        "We use a [LightningDataModule](https://lightning.ai/docs/pytorch/stable/data/datamodule.html) for handling the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMbJueDhUwiW"
      },
      "outputs": [],
      "source": [
        "class MNISTDataModule(LightningDataModule):\n",
        "    def __init__(self, data_dir: str = './data', batch_size: int = 32, num_workers: int = 4, transform = transforms.ToTensor()):\n",
        "        super().__init__()\n",
        "        self.data_dir = data_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "        self.transform = transform\n",
        "\n",
        "        self.test_set = MNIST(self.data_dir, train=False, transform=self.transform, download=True)\n",
        "        dev_set = MNIST(self.data_dir, train=True, transform=self.transform, download=True)\n",
        "        self.train_set, self.val_set = random_split(dev_set, [55000, 5000])\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_set, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers, persistent_workers=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val_set, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers, persistent_workers=True)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test_set, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers, persistent_workers=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98TeNGIsUwiX"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PxT1ah3UwiX"
      },
      "source": [
        "We use a [LightningModule](https://lightning.ai/docs/pytorch/stable/common/lightning_module.html) for implementing the model and its training and testing steps.\n",
        "\n",
        "**Task:** Replace the single-layer network with a LeNet-like CNN architecture. You need to add the model layers and change the forward pass accordingly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzHCJLnbUwiX"
      },
      "outputs": [],
      "source": [
        "class ImageClassifier(LightningModule):\n",
        "    def __init__(self, input_dim: tuple[int, int] = (28,28), output_dim: int = 10, learning_rate: float = 0.001):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        # single-layer network (logistic regression-like)\n",
        "        self.fc_layer = nn.Linear(torch.prod(torch.tensor(self.input_dim)), self.output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc_layer(x)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        return optimizer\n",
        "\n",
        "    def process_batch(self, batch):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = F.cross_entropy(logits, y)\n",
        "\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        preds = torch.argmax(probs, dim=1)\n",
        "        acc = accuracy(preds, y, task='multiclass', num_classes=self.output_dim)\n",
        "\n",
        "        return loss, acc\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss, acc = self.process_batch(batch)\n",
        "        self.log('train_loss', loss, prog_bar=True)\n",
        "        self.log('train_acc', acc, prog_bar=True)\n",
        "        if batch_idx == 0:\n",
        "            grid = torchvision.utils.make_grid(batch[0][0:16, ...], nrow=4, normalize=True)\n",
        "            self.logger.experiment.add_image('train_images', grid, self.global_step)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        loss, acc = self.process_batch(batch)\n",
        "        self.log('val_loss', loss, prog_bar=True)\n",
        "        self.log('val_acc', acc, prog_bar=True)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        loss, acc = self.process_batch(batch)\n",
        "        self.log('test_loss', loss)\n",
        "        self.log('test_acc', acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbMRymXcUwiY"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrA_WfJsUwiZ"
      },
      "source": [
        "We use the PyTorch Lightning [Trainer](https://lightning.ai/docs/pytorch/stable/common/trainer.html) for training and testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CND8lZ5DUwiZ"
      },
      "outputs": [],
      "source": [
        "seed_everything(42, workers=True)\n",
        "\n",
        "data = MNISTDataModule(data_dir='./data', batch_size=32)\n",
        "\n",
        "model = ImageClassifier(input_dim=(28,28), output_dim=10, learning_rate=0.001)\n",
        "\n",
        "trainer = Trainer(\n",
        "    max_epochs=10,\n",
        "    accelerator='auto',\n",
        "    devices=1,\n",
        "    logger=TensorBoardLogger(save_dir='./lightning_logs/classification/', name='mnist-logreg'),\n",
        "    callbacks=[ModelCheckpoint(monitor='val_loss', mode='min'), TQDMProgressBar(refresh_rate=10)],\n",
        ")\n",
        "trainer.fit(model=model, datamodule=data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wR5DTMZUwia"
      },
      "source": [
        "## Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouPK6z-XUwia"
      },
      "source": [
        "Evaluate the trained model with the best checkpoint on the validation data and report the classification accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdtTdS4UUwia"
      },
      "outputs": [],
      "source": [
        "trainer.validate(model=model, datamodule=data, ckpt_path=trainer.checkpoint_callback.best_model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1-I3U_NUwia"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwaxKfbeUwib"
      },
      "source": [
        "Evaluate the trained model with the best checkpoint on the test data and report the classification accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anmO-Qe2Uwib"
      },
      "outputs": [],
      "source": [
        "trainer.test(model=model, datamodule=data, ckpt_path=trainer.checkpoint_callback.best_model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brD4toz0Uwib"
      },
      "source": [
        "## Testing on out-of-distribution data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XISIeBR4Uwic"
      },
      "source": [
        "Here we prepare an out-of-distribution test set where all digits are shifted by two pixels. We then test the trained model and report the classification accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cicS8qM4Uwic"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.CenterCrop((26,26)),\n",
        "    transforms.Pad((0,0,2,2)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "data_ood = MNISTDataModule(data_dir='./data', batch_size=32, transform=transform)\n",
        "\n",
        "trainer.test(model=model, datamodule=data_ood, ckpt_path=trainer.checkpoint_callback.best_model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxbZKxoKUwic"
      },
      "source": [
        "## Visualisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Li_dPdb6Uwic"
      },
      "source": [
        "### Test data examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-HofbrrUwid"
      },
      "source": [
        "Let's compare the original, in-distribution and the out-of-distribution test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYxpq1p-Uwid"
      },
      "outputs": [],
      "source": [
        "samples_iid = [data.test_set[i][0] for i in range(0,16)]\n",
        "samples_ood = [data_ood.test_set[i][0] for i in range(0,16)]\n",
        "grid_iid = torchvision.utils.make_grid(samples_iid, nrow=4, normalize=True).numpy()[0,...].squeeze()\n",
        "grid_ood = torchvision.utils.make_grid(samples_ood, nrow=4, normalize=True).numpy()[0,...].squeeze()\n",
        "\n",
        "f, ax = plt.subplots(1,3, figsize=(15, 15))\n",
        "\n",
        "ax[0].imshow(grid_iid, cmap=matplotlib.cm.gray)\n",
        "ax[0].axis('off')\n",
        "ax[0].set_title('in-distribution')\n",
        "\n",
        "ax[1].imshow(grid_ood, cmap=matplotlib.cm.gray)\n",
        "ax[1].axis('off')\n",
        "ax[1].set_title('out-of-distribution')\n",
        "\n",
        "ax[2].imshow(grid_iid - grid_ood, cmap=matplotlib.cm.bwr)\n",
        "ax[2].axis('off')\n",
        "ax[2].set_title('difference')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5Ge3UEpUwid"
      },
      "source": [
        "### Weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAfP4BtKUwie"
      },
      "source": [
        "Let's inspect the patterns that the single-layer network has learned for each digit class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAL_dTKCUwie"
      },
      "outputs": [],
      "source": [
        "weights = model.fc_layer.weight.detach().cpu().numpy()\n",
        "\n",
        "f, ax = plt.subplots(1,10, figsize=(15, 15))\n",
        "\n",
        "for i in range(0,10):\n",
        "    vmax = np.max(np.abs(weights[i,:])) / 2\n",
        "    ax[i].imshow(weights[i,:].reshape(28,28), cmap=matplotlib.cm.bwr, clim=(-vmax,vmax))\n",
        "    ax[i].axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWv8RD0VUwie"
      },
      "source": [
        "## Logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVPwInPuUwif"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir './lightning_logs/classification/'"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mli-tutorials",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}